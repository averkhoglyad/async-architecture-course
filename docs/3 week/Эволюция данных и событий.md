### Эволюция данных

При развитии приложения возникает необходимость изменения текущей схемы данных. Для миграции схемы данных в БД сейчас используется `liquibase`. В текущей реализации для Д/З миграция запускается при старте сервера, но в реальных прод системах это приводит к проблемам:
- запуск нескольких инстансов одновременно (решается на уровне самой библиотеки)
- требуется перезапуск инстанса(ов)
- миграции могут быть длительными и всё это время инстанс будет "простаивать" (ждать завершения миграции)

Для решения этой проблемы запуск миграции выносим за пределы сервера (в отдельный модуль, директорию, etc), запускаем отдельно по CI/CD pipeline'у (так же может запускаться вручную или согласно иной стратегии). После применения миграции выкатывается код (например по схеме n+1 - запускается 1 новый сервер и затем тушится старый и заменяется на новый пока не обновится весь пул инстансов). Миграции схемы данных обязательно должны быть обратно совместимы со старым кодом, чтобы код мог продолжать работать в процессе и после миграции. При этом события оставляем работать как есть, в старой версии. После полного того как все сервисы обновились и работают с новой версией БД, из её схемы можно убирать устаревшие колонки, таблицы, конструкции, etc. 

### Эволюция событий

После того как обновился функционал сервиса приступаем к изменению событий. Разрабатываем новую схему данных для события и добавляем в schema-registry. В Д/З для этого используется отдельный модуль `schema`, который подключается в других сервисах и используется для валидации отправляемых и принимаемых событий. Для этого в модуле есть специальный Kafka `Serializer` и `Deserializer`, который берет из хедера сообщения имя и версию события, загружает схему и валидирует принятое сообщение. В других сервисах в конфигах Kafka подключаются данные (де)сериализаторы и оборачивают оригинальные (конфиги вынесены за рамки PR).

В первую очередь добавляем поддержку новой версии во все консумеры и на уровне настроек по хедерам определяем пришедшую версию события и десериализуем в соответствующий ДТО. При этом оставляя совместимость со старой версией события, которые продолжают поступать. Для того чтобы быть уверенными, что все консумеры перешли на новую версию, мы можем расширить `schema` и добавить actuator-метод который будет возвращать используемые версии событий (требуется доп. реализация). Для проверки мы получаем список запущенных сервисов из discovery-сервиса (требуется доп. настройка) и получаем из этого метода список используемых версий. После того как все консумеры обновили версию события и готовы переходить на новую, мы дорабатываем продюсер и переводим его на новую актуальную версию. Используемые версии также можно контролировать через actuator-метод и discovery-сервис.

### Состояние системы в Д/З

Для простоты реализации миграции включены в артефакт сервера и запускаются при старте.
По коду на данный момент `task-tracker` уже перешёл на новую схему данных и api и работает и принимает в Task поле jiraId, но продолжает отправлять в событии заголовок в старом формате с jiraId в поле title. В `schema` добавлена новая версия событий `Streaming-Task`. Так же сервис `accounting` уже поддерживает новую версию. Для простоты реализации я не выделял отдельно версию ДТО для разных версий, хотя это и можно было сделать, я сразу добавил опциональное поле `jiraId` и если оно не задано вытаскиваю его из title. После того как изменение будет применено в `analytics`, можно будет проапгрейдить продюсер в `task-tracker`.